# Reference List

1.  **Paper Name**: **Emergent Abilities of Large Language Models** (Wei, et al., 2022)
    *   **Summary**: Argues that as models scale, abilities not seen in smaller models "emerge" unpredictably. Essential to cite and discuss as a strong counterargument to this paper's view of a "symbolic processing engine."
    *   **URL**: `https://arxiv.org/abs/2206.07682`
    *   **File Name**: `Emergent_Abilities_of_Large_Language_Models.pdf`
    *   **Review Status**: Peer-reviewed (TMLR)

2.  **Paper Name**: **Chain-of-Thought Prompting Elicits Reasoning in Large Language Models** (Wei, et al., 2022)
    *   **Summary**: A seminal study showing that including intermediate reasoning steps (Chain-of-Thought) in prompts improves the complex reasoning abilities of LLMs.
    *   **URL**: `https://arxiv.org/abs/2201.11903`
    *   **File Name**: `Chain-of-Thought_Prompting_Elicits_Reasoning_in_Large_Language_Models.pdf`
    *   **Review Status**: Peer-reviewed (NeurIPS 2022)

3.  **Paper Name**: **Program-Aided Language Models (PAL)** (Gao, et al., 2022)
    *   **Summary**: A method that ensures computational accuracy by having an LLM generate a program and delegating its execution to an external deterministic tool like a Python interpreter.
    *   **URL**: `https://arxiv.org/abs/2211.10435`
    *   **File Name**: `Program-Aided_Language_Models.pdf`
    *   **Review Status**: Peer-reviewed (ICLR 2023)

4.  **Paper Name**: **The Next Decade in AI: Four Steps Towards Robust Artificial Intelligence** (Marcus, 2020)
    *   **Summary**: A paper by prominent AI researcher Gary Marcus, criticizing the current deep learning-centric approach and arguing for the importance of hybrid approaches incorporating symbolic reasoning.
    *   **URL**: `https://arxiv.org/abs/2002.06177`
    *   **File Name**: `The_Next_Decade_in_AI_Four_Steps_Towards_Robust_Artificial_Intelligence.pdf`
    *   **Review Status**: Preprint

5.  **Paper Name**: **Tree of Thoughts: Deliberate Problem Solving with Large Language Models** (Yao, et al., 2023)
    *   **Summary**: Improves complex problem-solving abilities by extending Chain-of-Thought (CoT) into a tree structure, allowing for the exploration, evaluation, and backtracking of multiple reasoning paths.
    *   **URL**: `https://arxiv.org/abs/2305.10601`
    *   **File Name**: `Tree_of_Thoughts_Deliberate_Problem_Solving_with_Large_Language_Models.pdf`
    *   **Review Status**: Peer-reviewed (NeurIPS 2023)

6.  **Paper Name**: **Graph of Thoughts: Solving Elaborate Problems with Large Language Models** (Besta, et al., 2023)
    *   **Summary**: Further generalizes thoughts into a graph structure, enabling thought fusion and loops, proposing a more flexible and powerful framework for problem-solving.
    *   **URL**: `https://arxiv.org/abs/2308.09687`
    *   **File Name**: `Graph_of_Thoughts_Solving_Elaborate_Problems_with_Large_Language_Models.pdf`
    *   **Review Status**: Peer-reviewed (ICLR 2024)

7.  **Paper Name**: **The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A"** (Berglund, et al., 2023)
    *   **Summary**: Points out the "Reversal Curse" phenomenon, where even after learning "A is B," the model cannot infer the symmetric relationship "B is A." Strong evidence that LLMs rely heavily on superficial forward patterns rather than true logical reasoning.
    *   **URL**: `https://arxiv.org/abs/2309.12288`
    *   **File Name**: `The_Reversal_Curse_LLMs_trained_on_A_is_B_fail_to_learn_B_is_A.pdf`
    *   **Review Status**: Peer-reviewed (ICLR 2024)

8.  **Paper Name**: **A Survey of Large Language Models** (Zhao, et al., 2023)
    *   **Summary**: A comprehensive survey paper summarizing the technology, resources, and future directions of large language models up to early 2023.
    *   **URL**: `https://arxiv.org/abs/2303.18223`
    *   **File Name**: `A_Survey_of_Large_Language_Models.pdf`
    *   **Review Status**: Preprint

9.  **Paper Name**: **Are Emergent Abilities of Large Language Models a Mirage?** (Schaeffer, et al., 2023 - *central to discussions from 2024 onwards*)
    *   **Summary**: Argues that "emergent abilities" are a "mirage" caused by non-linear performance metrics, and are in fact predictable and continuous improvements. A crucial critique for this paper, potentially overturning the view of emergence = unknown intelligence.
    *   **URL**: `https://arxiv.org/abs/2304.15004`
    *   **File Name**: `Are_Emergent_Abilities_of_Large_Language_Models_a_Mirage.pdf`
    *   **Review Status**: Peer-reviewed (NeurIPS 2023)

10. **Paper Name**: **Prompt Engineering Techniques for Language Model Reasoning Lack Replicability** (Vaugrante, et al., 2025)
    *   **Summary**: Points out the lack of replicability in Zero-shot Prompting Techniques (PET). Shows that many PETs are benchmark and model-dependent with no statistically significant differences, and calls for strict evaluation guidelines.
    *   **URL**: `https://openreview.net/forum?id=bgjR5bM44u`
    *   **File Name**: `Prompt_Engineering_Techniques_for_Language_Model_Reasoning_Lack_Replicability.pdf`
    *   **Review Status**: Under review at TMLR (Submitted to OpenReview Aug 16, 2025)

11. **Paper Name**: **Prompt Engineering Guidelines for Using Large Language Models in Requirements Engineering** (Ronanki, et al., 2025)
    *   **Summary**: Investigates prompt engineering guidelines against the backdrop of the importance of LLM output quality and accuracy in Requirements Engineering (RE). Through a systematic review and expert interviews, it reveals the lack of RE-specific guidelines and points to future research directions.
    *   **URL**: `https://arxiv.org/abs/2507.03405`
    *   **File Name**: `Prompt_Engineering_Guidelines_for_Using_Large_Language_Models_in_Requirements_Engineering.pdf`
    *   **Review Status**: Preprint (Published on arXiv Jul 4, 2025)

12. **Paper Name**: **Prompt Engineering and the Effectiveness of Large Language Models in Enhancing Human Productivity** (Anam, 2025)
    *   **Summary**: Investigates how the structure and clarity of user prompts affect the effectiveness and productivity of LLM outputs. Based on data from 243 respondents, it finds that users who employ clear, structured, and context-aware prompts achieve higher task efficiency and better outcomes.
    *   **URL**: `https://arxiv.org/abs/2507.18638`
    *   **File Name**: `Prompt_Engineering_and_the_Effectiveness_of_Large_Language_Models_in_Enhancing_Human_Productivity.pdf`
    *   **Review Status**: Preprint (Published on arXiv May 10, 2025, v2 Aug 27, 2025)